{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FITCHECK PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# # Loop through the folder to find .xlsx files\n",
    "base_folder = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6\"\n",
    "\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f'file_path = \"{file_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Variables here\n",
    "import os\n",
    "\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/DMZ_PROD_CISCO_WEB_WIN_1/DMZ_PROD_CISCO_WEB_WIN-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/DMZ_PROD_CISCO_APP_WIN_1/DMZ_PROD_CISCO_APP_WIN-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_CISCO_APPWEB_WIN-1/CORP_PROD_CISCO_APPWEB_WIN-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_HPE_APPWEB_WIN_2/CORP_PROD_HPE_APPWEB_WIN-2.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/collector/CORP_PROD_NU_HPE_DEH_APPWEB-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_DELL_SAS_VIYA_APPWEB-2/ntnxcollector2025_9_17_17_16_9.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_CISCO_ORADB-1/CORP_PROD_CISCO_ORADB-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/DMZ_PROD_CISCO_SQLDB_1/DMZ_PROD_CISCO_SQLDB-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_CISCO_APPWEB_LIN-1/CORP_PROD_CISCO_APPWEB_LIN-1.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_CISCO_APPWEB_WIN-2/CORP_PROD_CISCO_APPWEB_WIN-2.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_HPE_SQLDB_2/CORP_PROD_HPE_SQLDB-2.xlsx\"\n",
    "# file_path = \"/Users/ayush.srivastava/Downloads/Fitcheck_delivery/data/Reports/batch 6/CORP_PROD_HPE_APPWEB_WIN_1/CORP_PROD_HPE_APPWEB_WIN-1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty text file named \"vm_stats.txt\" in the same folder as the Excel file\n",
    "import os\n",
    "print(file_path)\n",
    "\n",
    "# Create the text file in the same directory as the Excel file\n",
    "txt_file_path = os.path.join(os.path.dirname(file_path), \"vm_stats.txt\")\n",
    "\n",
    "with open(txt_file_path, \"w\") as f:\n",
    "    f.write(\"hello\")\n",
    "    print(\"file created!!!\")\n",
    "    pass  # Just create the file, do not write anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get a list of all sheet names in the Excel file\n",
    "sheet_names = pd.ExcelFile(file_path).sheet_names\n",
    "\n",
    "# Print all sheet names\n",
    "print(\"Available sheets in the Excel file:\")\n",
    "for i, sheet in enumerate(sheet_names, 1):\n",
    "    print(f\"{i}. {sheet}\")\n",
    "\n",
    "# Count the number of sheets\n",
    "print(f\"\\nTotal number of sheets: {len(sheet_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = \"vMemory\"  # Replace with your actual sheet name\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "\n",
    "new_df = df[['VM Name', 'Size (MiB)', 'Peak %', 'Average %']]\n",
    "df = new_df.sort_values(by='Peak %', ascending=False)\n",
    "\n",
    "# Set up bar positions\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(df[\"VM Name\"]))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.bar(x - bar_width, df[\"Peak %\"], width=bar_width, label=\"Peak %\", color=\"#7855fa\")\n",
    "plt.bar(x, df[\"Average %\"], width=bar_width, label=\"Average %\", color=\"#131313\")\n",
    "plt.bar(x + bar_width, df[\"Size (MiB)\"]/1000, width=bar_width, label=\"Size (GB)\", color=\"#aaaaaa\")\n",
    "\n",
    "# Formatting\n",
    "plt.xticks(x, df[\"VM Name\"], rotation=90)\n",
    "plt.ylabel(\"Memory Usage (%)\")\n",
    "plt.title(\"Memory Usage and Allocation per VM\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add text annotations for memory size in GB\n",
    "for i, v in enumerate(df['Size (MiB)']):\n",
    "    size_gb = v/1024  # Convert MiB to GiB\n",
    "    plt.text(i + bar_width, v/1000 + 0.5, f\"{size_gb:.1f} GB\", \n",
    "             color='black', fontweight='bold', ha='center', va='bottom', \n",
    "             rotation=90, fontsize=8)\n",
    "\n",
    "# Save the plot as an image in the same directory as the Excel file\n",
    "plot_path = os.path.join(os.path.dirname(file_path), \"memory_usage.png\")\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "\n",
    "# Create a new dataframe for memory analysis\n",
    "memory_analysis = df.copy()\n",
    "\n",
    "# Calculate memory utilization thresholds\n",
    "memory_analysis['Over 80% Avg'] = memory_analysis['Average %'] > 80\n",
    "memory_analysis['Under 20% Avg'] = memory_analysis['Average %'] < 20\n",
    "\n",
    "# Identify high memory usage VMs\n",
    "high_memory_vms = memory_analysis[memory_analysis['Over 80% Avg'] == True]\n",
    "high_mem_lines = [f\"VMs with AVERAGE memory usage exceeding 80%:\"]\n",
    "if len(high_memory_vms) > 0:\n",
    "    for index, row in high_memory_vms.iterrows():\n",
    "        high_mem_lines.append(f\"{row['VM Name']}: {row['Average %']:.2f}% (of {row['Size (MiB)']/1024:.1f} GB)\")\n",
    "else:\n",
    "    high_mem_lines.append(\"No VMs found with average memory usage exceeding 80%\")\n",
    "\n",
    "# Identify low memory usage VMs\n",
    "low_memory_vms = memory_analysis[memory_analysis['Under 20% Avg'] == True]\n",
    "low_mem_lines = [f\"\\nVMs with AVERAGE memory usage under 20%:\"]\n",
    "if len(low_memory_vms) > 0:\n",
    "    low_mem_lines.append(f\"Total count: {len(low_memory_vms)} VMs\")\n",
    "    # Sort by memory size to highlight large underutilized VMs first\n",
    "    sorted_low_mem = low_memory_vms.sort_values(by='Size (MiB)', ascending=False)\n",
    "    # List all underutilized VMs\n",
    "    for index, row in sorted_low_mem.iterrows():\n",
    "        low_mem_lines.append(f\"{row['VM Name']}: {row['Average %']:.2f}% (of {row['Size (MiB)']/1024:.1f} GB)\")\n",
    "else:\n",
    "    low_mem_lines.append(\"No VMs found with average memory usage under 20%\")\n",
    "\n",
    "# Write stats to vm_stats.txt in the same directory as the Excel file\n",
    "stats_file_path = os.path.join(os.path.dirname(file_path), \"vm_stats.txt\")\n",
    "with open(stats_file_path, \"w\") as f:\n",
    "    for line in high_mem_lines + low_mem_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "# Print to console as before\n",
    "for line in high_mem_lines:\n",
    "    print(line)\n",
    "for line in low_mem_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sheet_name = \"vCPU\"  # Replace with your actual sheet name\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "new_df = df[['VM Name', 'vCPUs', 'Peak %', 'Average %']]\n",
    "# new_df.head(20)\n",
    "\n",
    "# Sort the data by Peak % to better visualize VM performance\n",
    "sorted_df = new_df.sort_values(by='Peak %', ascending=False)\n",
    "\n",
    "# Set up bar positions\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(sorted_df))\n",
    "\n",
    "# Create plot with multiple metrics\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plot bars for each metric\n",
    "plt.bar(x - bar_width, sorted_df['Peak %'], width=bar_width, label='Peak %', color='#7855fa')\n",
    "plt.bar(x, sorted_df['Average %'], width=bar_width, label='Average %', color='#131313')\n",
    "plt.bar(x + bar_width, sorted_df['vCPUs']/2, width=bar_width, label='vCPUs (scaled รท2)', color='#aaaaaa')\n",
    "\n",
    "# Add formatting\n",
    "plt.xlabel('VM Name')\n",
    "plt.ylabel('Usage %')\n",
    "plt.title('CPU Usage and vCPU Allocation by VM')\n",
    "plt.xticks(x, sorted_df['VM Name'], rotation=90)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add text annotations for vCPU counts\n",
    "for i, v in enumerate(sorted_df['vCPUs']):\n",
    "    plt.text(i + bar_width, v/2 + 0.5, str(v), color='black', fontweight='bold', \n",
    "             ha='center', va='bottom', rotation=0, fontsize=8)\n",
    "\n",
    "# Save the CPU plot as an image in the same directory as the Excel file\n",
    "cpu_plot_path = os.path.join(os.path.dirname(file_path), \"cpu_usage.png\")\n",
    "plt.savefig(cpu_plot_path)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create a dataframe for CPU analysis\n",
    "cpu_analysis = sorted_df.copy()\n",
    "\n",
    "# Calculate CPU utilization thresholds\n",
    "cpu_analysis['Over 80% Peak'] = cpu_analysis['Peak %'] > 80\n",
    "cpu_analysis['Over 80% Avg'] = cpu_analysis['Average %'] > 80\n",
    "cpu_analysis['Under 20% Avg'] = cpu_analysis['Average %'] < 20\n",
    "\n",
    "# Identify high CPU usage VMs (peak)\n",
    "high_cpu_peak = cpu_analysis[cpu_analysis['Over 80% Peak'] == True]\n",
    "print(f\"VMs with PEAK CPU usage exceeding 80%:\")\n",
    "if len(high_cpu_peak) > 0:\n",
    "    print(f\"Total count: {len(high_cpu_peak)} VMs\")\n",
    "    for index, row in high_cpu_peak.head(10).iterrows():\n",
    "        print(f\"{row['VM Name']}: {row['Peak %']:.2f}% peak, {row['Average %']:.2f}% avg ({row['vCPUs']} vCPUs)\")\n",
    "    if len(high_cpu_peak) > 10:\n",
    "        print(f\"... and {len(high_cpu_peak) - 10} more VMs with >80% peak CPU usage\")\n",
    "else:\n",
    "    print(\"No VMs found with peak CPU usage exceeding 80%\")\n",
    "\n",
    "# Identify high CPU usage VMs (average)\n",
    "high_cpu_avg = cpu_analysis[cpu_analysis['Over 80% Avg'] == True]\n",
    "print(f\"\\nVMs with AVERAGE CPU usage exceeding 80%:\")\n",
    "if len(high_cpu_avg) > 0:\n",
    "    for index, row in high_cpu_avg.iterrows():\n",
    "        print(f\"{row['VM Name']}: {row['Average %']:.2f}% avg, {row['Peak %']:.2f}% peak ({row['vCPUs']} vCPUs)\")\n",
    "else:\n",
    "    print(\"No VMs found with average CPU usage exceeding 80%\")\n",
    "\n",
    "# Identify low CPU usage VMs\n",
    "low_cpu_vms = cpu_analysis[cpu_analysis['Under 20% Avg'] == True]\n",
    "print(f\"\\nVMs with AVERAGE CPU usage under 20%:\")\n",
    "if len(low_cpu_vms) > 0:\n",
    "    print(f\"Total count: {len(low_cpu_vms)} VMs\")\n",
    "    # Show top 10 VMs with high vCPU count but low usage\n",
    "    sorted_low_cpu = low_cpu_vms.sort_values(by='vCPUs', ascending=False)\n",
    "    for index, row in sorted_low_cpu.head(10).iterrows():\n",
    "        print(f\"{row['VM Name']}: {row['Average %']:.2f}% avg, {row['Peak %']:.2f}% peak ({row['vCPUs']} vCPUs)\")\n",
    "    if len(low_cpu_vms) > 10:\n",
    "        print(f\"... and {len(low_cpu_vms) - 10} more VMs with <20% average CPU usage\")\n",
    "else:\n",
    "    print(\"No VMs found with average CPU usage under 20%\")\n",
    "\n",
    "# Calculate potential CPU consolidation\n",
    "total_vcpus = sorted_df['vCPUs'].sum()\n",
    "low_usage_vcpus = low_cpu_vms['vCPUs'].sum()\n",
    "print(f\"\\nPotential CPU optimization:\")\n",
    "print(f\"Total vCPUs across all VMs: {total_vcpus}\")\n",
    "print(f\"vCPUs in low-usage VMs (<20% avg): {low_usage_vcpus} ({low_usage_vcpus/total_vcpus*100:.2f}% of total)\")\n",
    "\n",
    "# Prepare CPU stats for writing\n",
    "cpu_stats_lines = []\n",
    "# High CPU usage (peak)\n",
    "cpu_stats_lines.append(\"\\nVMs with PEAK CPU usage exceeding 80%:\")\n",
    "if len(high_cpu_peak) > 0:\n",
    "    cpu_stats_lines.append(f\"Total count: {len(high_cpu_peak)} VMs\")\n",
    "    for index, row in high_cpu_peak.iterrows():\n",
    "        cpu_stats_lines.append(f\"{row['VM Name']}: {row['Peak %']:.2f}% peak, {row['Average %']:.2f}% avg ({row['vCPUs']} vCPUs)\")\n",
    "else:\n",
    "    cpu_stats_lines.append(\"No VMs found with peak CPU usage exceeding 80%\")\n",
    "# High CPU usage (average)\n",
    "cpu_stats_lines.append(\"\\nVMs with AVERAGE CPU usage exceeding 80%:\")\n",
    "if len(high_cpu_avg) > 0:\n",
    "    for index, row in high_cpu_avg.iterrows():\n",
    "        cpu_stats_lines.append(f\"{row['VM Name']}: {row['Average %']:.2f}% avg, {row['Peak %']:.2f}% peak ({row['vCPUs']} vCPUs)\")\n",
    "else:\n",
    "    cpu_stats_lines.append(\"No VMs found with average CPU usage exceeding 80%\")\n",
    "# Low CPU usage\n",
    "cpu_stats_lines.append(\"\\nVMs with AVERAGE CPU usage under 20%:\")\n",
    "if len(low_cpu_vms) > 0:\n",
    "    cpu_stats_lines.append(f\"Total count: {len(low_cpu_vms)} VMs\")\n",
    "    sorted_low_cpu = low_cpu_vms.sort_values(by='vCPUs', ascending=False)\n",
    "    for index, row in sorted_low_cpu.iterrows():\n",
    "        cpu_stats_lines.append(f\"{row['VM Name']}: {row['Average %']:.2f}% avg, {row['Peak %']:.2f}% peak ({row['vCPUs']} vCPUs)\")\n",
    "else:\n",
    "    cpu_stats_lines.append(\"No VMs found with average CPU usage under 20%\")\n",
    "# CPU optimization\n",
    "cpu_stats_lines.append(\"\\nPotential CPU optimization:\")\n",
    "cpu_stats_lines.append(f\"Total vCPUs across all VMs: {total_vcpus}\")\n",
    "cpu_stats_lines.append(f\"vCPUs in low-usage VMs (<20% avg): {low_usage_vcpus} ({low_usage_vcpus/total_vcpus*100:.2f}% of total)\")\n",
    "\n",
    "# Append CPU stats to vm_stats.txt\n",
    "stats_file_path = os.path.join(os.path.dirname(file_path), \"vm_stats.txt\")\n",
    "with open(stats_file_path, \"a\") as f:\n",
    "    for line in cpu_stats_lines:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the vDisk sheet from Excel file\n",
    "sheet_name = \"vmList\"  # Use the vDisk sheet instead of vCPU\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name, engine='openpyxl')\n",
    "\n",
    "# Extract relevant columns for disk analysis\n",
    "new_df = df[['VM Name', 'Capacity (MiB)', 'Consumed (MiB)']]\n",
    "\n",
    "# Calculate percentage of disk used and remaining space\n",
    "new_df['Consumed %'] = (new_df['Consumed (MiB)'] / new_df['Capacity (MiB)']) * 100\n",
    "new_df['Remaining (MiB)'] = new_df['Capacity (MiB)'] - new_df['Consumed (MiB)']\n",
    "\n",
    "# Create color mapping based on usage percentage\n",
    "colors = []\n",
    "for pct in new_df['Consumed %']:\n",
    "    if pct > 90:\n",
    "        colors.append('red')\n",
    "    elif pct > 80:\n",
    "        colors.append('orange')\n",
    "    elif pct > 70:\n",
    "        colors.append('yellow')\n",
    "    else:\n",
    "        colors.append('#7855fa')  # Use the same blue color as in previous plots\n",
    "\n",
    "# Convert MiB to GB for plotting\n",
    "new_df['Capacity (GB)'] = new_df['Capacity (MiB)'] / 1024\n",
    "new_df['Consumed (GB)'] = new_df['Consumed (MiB)'] / 1024\n",
    "new_df['Remaining (GB)'] = new_df['Remaining (MiB)'] / 1024\n",
    "\n",
    "# Sort the dataframe by Consumed % to easily identify high-usage VMs\n",
    "sorted_by_usage = new_df.sort_values(by='Consumed %', ascending=False)\n",
    "\n",
    "# Filter VMs with usage > 80%\n",
    "high_usage_vms = sorted_by_usage[sorted_by_usage['Consumed %'] > 80]\n",
    "\n",
    "# Print the high usage VMs\n",
    "print(\"VMs with storage usage exceeding 80%:\")\n",
    "if len(high_usage_vms) > 0:\n",
    "    for index, row in high_usage_vms.iterrows():\n",
    "        print(f\"{row['VM Name']}: {row['Consumed %']:.2f}% used ({row['Consumed (GB)']:.2f} GB / {row['Capacity (GB)']:.2f} GB)\")\n",
    "else:\n",
    "    print(\"No VMs found with storage usage exceeding 80%\")\n",
    "\n",
    "# Plot storage usage in GB\n",
    "plt.figure(figsize=(16, 7))\n",
    "x = np.arange(len(new_df))\n",
    "bar_width = 0.4\n",
    "\n",
    "# Use colors list for bar colors\n",
    "plt.bar(x, new_df['Consumed (GB)'], width=bar_width, label='Consumed (GB)', color=colors)\n",
    "plt.bar(x, new_df['Capacity (GB)'], width=bar_width, label='Capacity (GB)', color='#131313', alpha=0.2)\n",
    "\n",
    "plt.xlabel('VM Name')\n",
    "plt.ylabel('Storage (GB)')\n",
    "plt.title('VM Storage Usage (GB)')\n",
    "plt.xticks(x, new_df['VM Name'], rotation=90, fontsize=8)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add text annotations vertically\n",
    "for i, (consumed, remaining, percentage) in enumerate(zip(new_df['Consumed (GB)'], \n",
    "                                                         new_df['Remaining (GB)'],\n",
    "                                                         new_df['Consumed %'])):\n",
    "    plt.text(i, consumed + 2, f\"{remaining:.1f} GB\\n({percentage:.1f}%)\", \n",
    "            ha='center', va='bottom', fontsize=7, color='black', rotation=90)\n",
    "\n",
    "# Save the disk plot as an image in the same directory as the Excel file\n",
    "# (Save BEFORE plt.show() to avoid blank image)\n",
    "disk_plot_path = os.path.join(os.path.dirname(file_path), \"disk_usage.png\")\n",
    "plt.savefig(disk_plot_path)\n",
    "plt.show()\n",
    "\n",
    "# Prepare disk stats for writing\n",
    "disk_stats_lines = []\n",
    "disk_stats_lines.append(\"\\nVMs with storage usage exceeding 80%:\")\n",
    "if len(high_usage_vms) > 0:\n",
    "    disk_stats_lines.append(f\"Total count: {len(high_usage_vms)} VMs\")\n",
    "    for index, row in high_usage_vms.iterrows():\n",
    "        disk_stats_lines.append(f\"{row['VM Name']}: {row['Consumed %']:.2f}% used ({row['Consumed (GB)']:.2f} GB / {row['Capacity (GB)']:.2f} GB)\")\n",
    "else:\n",
    "    disk_stats_lines.append(\"No VMs found with storage usage exceeding 80%\")\n",
    "\n",
    "# Append disk stats to vm_stats.txt\n",
    "stats_file_path = os.path.join(os.path.dirname(file_path), \"vm_stats.txt\")\n",
    "with open(stats_file_path, \"a\") as f:\n",
    "    for line in disk_stats_lines:\n",
    "        f.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
